import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.86.0";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

const SUPABASE_URL = Deno.env.get("SUPABASE_URL")!;
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!;
const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);

// Normalize Brazilian phone number
function normalizePhone(phone: string): string {
  const clean = phone.replace(/\D/g, "").replace("@c.us", "").replace("@s.whatsapp.net", "");
  
  // Add country code if missing
  if (!clean.startsWith("55") && clean.length <= 11) {
    return "55" + clean;
  }
  
  return clean;
}

// Fetch conversation history for context
async function getConversationHistory(conversationId: string, limit = 20): Promise<Array<{ role: string; content: string }>> {
  const { data: messages } = await supabase
    .from("whatsapp_messages")
    .select("content, direction, created_at, message_type, media_caption")
    .eq("conversation_id", conversationId)
    .order("created_at", { ascending: false })
    .limit(limit);

  if (!messages || messages.length === 0) return [];

  // Convert to chat format (oldest first)
  return messages.reverse().map((msg) => ({
    role: msg.direction === "inbound" ? "user" : "assistant",
    content: msg.content || msg.media_caption || "[m√≠dia sem texto]",
  })).filter(m => m.content);
}

// Generate intelligent AI response based on conversation context
async function generateAIResponse(
  conversationHistory: Array<{ role: string; content: string }>,
  newMessage: string,
  leadInfo?: { name?: string; stage?: string; products?: string[] } | null
): Promise<string | null> {
  if (!LOVABLE_API_KEY) {
    console.log("LOVABLE_API_KEY not configured, skipping AI response");
    return null;
  }

  try {
    console.log("=== Generating AI response ===");
    console.log("History messages:", conversationHistory.length);
    console.log("New message:", newMessage?.substring(0, 100));

    const leadContext = leadInfo 
      ? `\n\nINFORMA√á√ïES DO LEAD NO CRM:
- Nome: ${leadInfo.name || "N√£o cadastrado"}
- Est√°gio do funil: ${leadInfo.stage || "N√£o definido"}
- Produtos de interesse: ${leadInfo.products?.join(", ") || "N√£o definido"}`
      : "";

    const systemPrompt = `Voc√™ √© uma assistente virtual inteligente e profissional para vendedores de um CRM de vendas chamado Morphews.

SEU PAPEL:
- Voc√™ ajuda vendedores a gerenciar leads, agendar reuni√µes e organizar informa√ß√µes de clientes
- Voc√™ analisa conversas para extrair dados relevantes (nomes, telefones, emails, datas de reuni√£o, etc.)
- Voc√™ √© proativa, educada e sempre busca ajudar o vendedor a fechar mais vendas

CAPACIDADES:
- Analisar imagens e screenshots para extrair informa√ß√µes de leads
- Transcrever √°udios automaticamente
- Identificar informa√ß√µes importantes em conversas
- Sugerir pr√≥ximos passos baseado no contexto
- Lembrar o contexto da conversa anterior

REGRAS:
1. Sempre analise o CONTEXTO das mensagens anteriores antes de responder
2. Se o usu√°rio enviar uma imagem com dados de lead/reuni√£o, extraia as informa√ß√µes E pergunte se quer cadastrar
3. Seja concisa mas completa
4. Use emojis moderadamente para ser amig√°vel
5. Se n√£o tiver certeza de algo, pergunte para confirmar
6. Priorize extrair: nome, telefone, email, data/hora de reuni√£o
7. Quando identificar uma reuni√£o marcada, confirme os detalhes: data, hora, com quem
${leadContext}

EXEMPLOS DE COMPORTAMENTO INTELIGENTE:
- Se o usu√°rio pedir "cadastrar reuni√£o" e antes enviou dados, use esses dados
- Se a conversa menciona "segunda 14:00", identifique isso como hor√°rio de reuni√£o
- Se identificar um nome na conversa, use-o para perguntar "Quer cadastrar [Nome] como lead?"`;

    const messages = [
      { role: "system", content: systemPrompt },
      ...conversationHistory.slice(-15), // Last 15 messages for context
      { role: "user", content: newMessage }
    ];

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("AI response error:", response.status, errorText);
      return null;
    }

    const data = await response.json();
    const aiResponse = data.choices?.[0]?.message?.content;
    
    console.log("=== AI response generated ===");
    console.log("Response preview:", aiResponse?.substring(0, 200));
    return aiResponse || null;
  } catch (error) {
    console.error("Error generating AI response:", error);
    return null;
  }
}

// Analyze image using Lovable AI (Gemini Vision)
async function analyzeImage(imageUrl: string, base64Data?: string): Promise<string | null> {
  if (!LOVABLE_API_KEY) {
    console.log("LOVABLE_API_KEY not configured, skipping image analysis");
    return null;
  }

  try {
    console.log("=== Starting image analysis ===");
    console.log("Image URL:", imageUrl?.substring(0, 100));
    console.log("Has base64 data:", !!base64Data);
    
    let base64Image: string;
    let mimeType = "image/jpeg";
    
    // Use base64 data if provided (preferred - doesn't expire)
    if (base64Data) {
      console.log("Using provided base64 data");
      base64Image = base64Data;
    } else if (imageUrl) {
      // Try to fetch from URL
      console.log("Fetching image from URL...");
      const imageResponse = await fetch(imageUrl, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
      });
      
      if (!imageResponse.ok) {
        console.error("Failed to fetch image:", imageResponse.status, imageResponse.statusText);
        return null;
      }
      
      const imageBuffer = await imageResponse.arrayBuffer();
      base64Image = btoa(String.fromCharCode(...new Uint8Array(imageBuffer)));
      mimeType = imageResponse.headers.get("content-type") || "image/jpeg";
      console.log("Image fetched successfully, size:", imageBuffer.byteLength, "mime:", mimeType);
    } else {
      console.log("No image URL or base64 provided");
      return null;
    }
    
    console.log("Calling Gemini Vision API...");
    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          {
            role: "system",
            content: `Voc√™ √© um assistente que analisa imagens enviadas por WhatsApp para extrair informa√ß√µes de leads e neg√≥cios.
            
Ao analisar a imagem, extraia informa√ß√µes relevantes como:
- Nomes de pessoas
- N√∫meros de telefone
- Emails
- Datas e hor√°rios de reuni√µes
- Informa√ß√µes de empresas
- Valores ou pre√ßos
- Qualquer texto leg√≠vel relevante

Responda de forma clara e concisa em portugu√™s, listando as informa√ß√µes encontradas.
Se for um print de conversa, resuma os pontos principais.
Se a imagem n√£o contiver informa√ß√µes de neg√≥cio relevantes, descreva brevemente o que voc√™ v√™.`
          },
          {
            role: "user",
            content: [
              {
                type: "text",
                text: "Analise esta imagem e extraia todas as informa√ß√µes relevantes:"
              },
              {
                type: "image_url",
                image_url: {
                  url: `data:${mimeType};base64,${base64Image}`
                }
              }
            ]
          }
        ],
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("Gemini Vision API error:", response.status, errorText);
      return null;
    }

    const data = await response.json();
    const analysis = data.choices?.[0]?.message?.content;
    
    console.log("=== Image analysis complete ===");
    console.log("Result preview:", analysis?.substring(0, 200));
    return analysis || null;
  } catch (error) {
    console.error("Error analyzing image:", error);
    return null;
  }
}

// Transcribe audio using OpenAI Whisper
async function transcribeAudio(audioUrl: string, base64Data?: string): Promise<string | null> {
  if (!OPENAI_API_KEY) {
    console.log("OPENAI_API_KEY not configured, skipping audio transcription");
    return null;
  }

  try {
    console.log("=== Starting audio transcription ===");
    console.log("Audio URL:", audioUrl?.substring(0, 100));
    console.log("Has base64 data:", !!base64Data);
    
    let audioBlob: Blob;
    
    // Use base64 data if provided
    if (base64Data) {
      console.log("Using provided base64 data for audio");
      const binaryString = atob(base64Data);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      audioBlob = new Blob([bytes], { type: 'audio/ogg' });
    } else if (audioUrl) {
      console.log("Fetching audio from URL...");
      const audioResponse = await fetch(audioUrl, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
      });
      
      if (!audioResponse.ok) {
        console.error("Failed to fetch audio:", audioResponse.status, audioResponse.statusText);
        return null;
      }
      
      audioBlob = await audioResponse.blob();
      console.log("Audio fetched successfully, size:", audioBlob.size);
    } else {
      console.log("No audio URL or base64 provided");
      return null;
    }
    
    // Prepare form data for Whisper API
    const formData = new FormData();
    formData.append("file", audioBlob, "audio.ogg");
    formData.append("model", "whisper-1");
    formData.append("language", "pt");
    
    console.log("Calling Whisper API...");
    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
      },
      body: formData,
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("Whisper API error:", response.status, errorText);
      return null;
    }

    const data = await response.json();
    const transcription = data.text;
    
    console.log("=== Audio transcription complete ===");
    console.log("Result:", transcription?.substring(0, 200));
    return transcription || null;
  } catch (error) {
    console.error("Error transcribing audio:", error);
    return null;
  }
}

// Find instance by different provider IDs
async function findInstance(identifier: string, provider?: string) {
  console.log("Finding instance by identifier:", identifier, "provider:", provider);
  
  // Try WasenderAPI first
  if (provider === "wasenderapi" || !provider) {
    // WasenderAPI sends the api_key as sessionId in webhooks
    const { data: wasenderByApiKey } = await supabase
      .from("whatsapp_instances")
      .select("*")
      .eq("wasender_api_key", identifier)
      .single();

    if (wasenderByApiKey) {
      console.log("Found instance by wasender_api_key:", wasenderByApiKey.id);
      return wasenderByApiKey;
    }

    // Try by session ID (numeric)
    const { data: wasenderInstance } = await supabase
      .from("whatsapp_instances")
      .select("*")
      .eq("wasender_session_id", identifier)
      .single();

    if (wasenderInstance) {
      console.log("Found instance by wasender_session_id:", wasenderInstance.id);
      return wasenderInstance;
    }

    // Try by internal ID
    const { data: byId } = await supabase
      .from("whatsapp_instances")
      .select("*")
      .eq("id", identifier)
      .single();

    if (byId) {
      console.log("Found instance by id:", byId.id);
      return byId;
    }
  }

  // Try Z-API
  const { data: zapiInstance } = await supabase
    .from("whatsapp_instances")
    .select("*")
    .eq("z_api_instance_id", identifier)
    .single();

  if (zapiInstance) {
    console.log("Found instance by z_api_instance_id:", zapiInstance.id);
    return zapiInstance;
  }

  console.error("Instance not found:", identifier);
  return null;
}

// Try to find existing lead by phone number
async function findLeadByPhone(organizationId: string, phone: string) {
  const normalizedPhone = normalizePhone(phone);
  
  // Generate possible phone formats
  const variants = [
    normalizedPhone,
    normalizedPhone.replace("55", ""),
    normalizedPhone.length === 13 ? normalizedPhone.slice(0, 4) + normalizedPhone.slice(5) : null,
    normalizedPhone.length === 12 ? normalizedPhone.slice(0, 4) + "9" + normalizedPhone.slice(4) : null,
  ].filter(Boolean);

  for (const variant of variants) {
    const { data: lead } = await supabase
      .from("leads")
      .select("id, name, whatsapp")
      .eq("organization_id", organizationId)
      .or(`whatsapp.ilike.%${variant}%,secondary_phone.ilike.%${variant}%`)
      .limit(1)
      .single();

    if (lead) return lead;
  }

  return null;
}

// Get or create conversation
async function getOrCreateConversation(
  instanceId: string,
  organizationId: string,
  phoneNumber: string,
  contactName?: string,
  contactProfilePic?: string
) {
  const normalizedPhone = normalizePhone(phoneNumber);
  
  // Try to find existing conversation
  const { data: existing } = await supabase
    .from("whatsapp_conversations")
    .select("*")
    .eq("instance_id", instanceId)
    .eq("phone_number", normalizedPhone)
    .single();

  if (existing) {
    // Update contact info if available
    if (contactName || contactProfilePic) {
      await supabase
        .from("whatsapp_conversations")
        .update({
          contact_name: contactName || existing.contact_name,
          contact_profile_pic: contactProfilePic || existing.contact_profile_pic,
          updated_at: new Date().toISOString(),
        })
        .eq("id", existing.id);
    }
    return existing;
  }

  // Try to find matching lead
  const lead = await findLeadByPhone(organizationId, normalizedPhone);

  // Create new conversation
  const { data: newConversation, error } = await supabase
    .from("whatsapp_conversations")
    .insert({
      instance_id: instanceId,
      organization_id: organizationId,
      phone_number: normalizedPhone,
      contact_name: contactName || lead?.name || null,
      contact_profile_pic: contactProfilePic || null,
      lead_id: lead?.id || null,
    })
    .select()
    .single();

  if (error) {
    console.error("Error creating conversation:", error);
    throw error;
  }

  return newConversation;
}

// Check if message already exists to avoid duplicates
async function messageExists(conversationId: string, messageId: string) {
  if (!messageId) return false;
  
  const { data } = await supabase
    .from("whatsapp_messages")
    .select("id")
    .eq("conversation_id", conversationId)
    .eq("z_api_message_id", messageId)
    .single();
  
  return !!data;
}

// Save message to database
async function saveMessage(
  conversationId: string,
  instanceId: string,
  content: string | null,
  direction: "inbound" | "outbound",
  messageType: string,
  messageId?: string,
  mediaUrl?: string,
  mediaCaption?: string,
  isFromBot = false
) {
  // Check for duplicates
  if (messageId && await messageExists(conversationId, messageId)) {
    console.log("Message already exists, skipping:", messageId);
    return null;
  }

  // Status must be: sent, delivered, read, or failed (constraint)
  const { data, error } = await supabase
    .from("whatsapp_messages")
    .insert({
      conversation_id: conversationId,
      instance_id: instanceId,
      content,
      direction,
      message_type: messageType,
      z_api_message_id: messageId || null,
      media_url: mediaUrl || null,
      media_caption: mediaCaption || null,
      is_from_bot: isFromBot,
      status: direction === "outbound" ? "sent" : "delivered",
    })
    .select()
    .single();

  if (error) {
    console.error("Error saving message:", error);
    throw error;
  }

  // Update conversation last_message_at and unread count
  const updateData: any = {
    last_message_at: new Date().toISOString(),
  };

  if (direction === "inbound") {
    const { data: conv } = await supabase
      .from("whatsapp_conversations")
      .select("unread_count")
      .eq("id", conversationId)
      .single();

    updateData.unread_count = (conv?.unread_count || 0) + 1;
  }

  await supabase
    .from("whatsapp_conversations")
    .update(updateData)
    .eq("id", conversationId);

  console.log("Message saved successfully:", data?.id);
  return data;
}

// Process WasenderAPI message payload - handles both messages.received and messages.upsert
async function processWasenderMessage(instance: any, body: any) {
  // WasenderAPI sends messages as object, not array!
  // Handle both: data.messages (object) and data.messages[0] (array format from other providers)
  let msgData = body.data?.messages;
  
  // If messages is an array, get first element
  if (Array.isArray(msgData)) {
    msgData = msgData[0];
  }
  // If messages is null/undefined, try other fields
  if (!msgData) {
    msgData = body.data?.message || body.data;
  }
  
  if (!msgData) {
    console.log("No message data in payload");
    return null;
  }

  console.log("Processing msgData:", JSON.stringify(msgData, null, 2));

  // Check if fromMe (our own message) - skip if already saved by send function
  const isFromMe = msgData.key?.fromMe === true;
  
  // Extract phone from various possible fields
  // IMPORTANT: WasenderAPI uses LID format (remoteJid ends with @lid) which is NOT a real phone number
  // We need to use senderPn or cleanedSenderPn which contains the actual phone number
  const remoteJid = msgData.key?.remoteJid || msgData.remoteJid || "";
  const isLidFormat = remoteJid.includes("@lid");
  
  let phone = "";
  
  // Prefer cleanedSenderPn or senderPn for actual phone number (these contain real phone numbers)
  if (msgData.key?.cleanedSenderPn) {
    phone = msgData.key.cleanedSenderPn;
  } else if (msgData.key?.senderPn) {
    phone = msgData.key.senderPn.replace("@s.whatsapp.net", "").replace("@c.us", "");
  } else if (!isLidFormat) {
    // Only use remoteJid if it's NOT in LID format
    phone = remoteJid.replace("@s.whatsapp.net", "").replace("@c.us", "").replace("@lid", "");
  }
  
  // Fallback to other phone fields
  if (!phone) {
    phone = msgData.from?.replace("@s.whatsapp.net", "").replace("@c.us", "") || 
            msgData.phone || "";
  }
  
  // If still using LID as fallback (no better option), log warning but continue
  if (!phone && isLidFormat) {
    console.log("WARNING: Using LID format as phone - sending messages may fail. RemoteJid:", remoteJid);
    phone = remoteJid.replace("@lid", "");
  }
  
  // Extract message content from various WasenderAPI formats
  let text = msgData.messageBody || 
            msgData.body ||
            msgData.text ||
            msgData.message?.conversation || 
            msgData.message?.extendedTextMessage?.text ||
            msgData.message?.imageMessage?.caption ||
            msgData.message?.videoMessage?.caption ||
            "";
  
  const messageId = msgData.key?.id || msgData.id || msgData.messageId || "";
  const isGroup = remoteJid.includes("@g.us") || msgData.isGroup || false;
  const senderName = msgData.pushName || msgData.senderName || msgData.name || "";
  
  // Determine message type
  let messageType = "text";
  if (msgData.message?.imageMessage || msgData.type === "image") messageType = "image";
  else if (msgData.message?.audioMessage || msgData.type === "audio" || msgData.type === "ptt") messageType = "audio";
  else if (msgData.message?.videoMessage || msgData.type === "video") messageType = "video";
  else if (msgData.message?.documentMessage || msgData.type === "document") messageType = "document";
  else if (msgData.message?.stickerMessage) messageType = "sticker";
  
  let mediaUrl = msgData.mediaUrl || 
                msgData.message?.imageMessage?.url ||
                msgData.message?.audioMessage?.url ||
                msgData.message?.videoMessage?.url ||
                msgData.message?.documentMessage?.url ||
                null;
  const caption = msgData.message?.imageMessage?.caption || 
                 msgData.message?.videoMessage?.caption ||
                 msgData.caption || 
                 null;

  // Try to get base64 data from payload (WasenderAPI sometimes includes it)
  const base64Data = msgData.base64 || 
                     msgData.mediaBase64 || 
                     msgData.message?.imageMessage?.base64 ||
                     msgData.message?.audioMessage?.base64 ||
                     msgData.message?.videoMessage?.base64 ||
                     msgData.data?.base64 ||
                     null;

  console.log("=== Parsed WasenderAPI message ===");
  console.log("Phone:", phone);
  console.log("Text preview:", text?.substring(0, 50));
  console.log("Message ID:", messageId);
  console.log("Sender:", senderName);
  console.log("Is from me:", isFromMe);
  console.log("Message type:", messageType);
  console.log("Has media URL:", !!mediaUrl);
  console.log("Media URL preview:", mediaUrl?.substring(0, 80));
  console.log("Has base64:", !!base64Data);

  if (!phone) {
    console.log("No phone number in message, msgData keys:", Object.keys(msgData));
    return null;
  }

  // Skip group messages
  if (isGroup) {
    console.log("Group message, skipping...");
    return null;
  }

  // Process media: analyze images and transcribe audio (only for incoming messages)
  let processedContent = text || caption || null;
  
  if (!isFromMe && (mediaUrl || base64Data)) {
    console.log("=== Processing media content ===");
    console.log("Processing for message type:", messageType);
    
    // Process image - analyze with Gemini Vision
    if (messageType === "image") {
      console.log("Starting image analysis...");
      const imageAnalysis = await analyzeImage(mediaUrl || "", base64Data);
      console.log("Image analysis result:", imageAnalysis ? "Success" : "Failed/Empty");
      if (imageAnalysis) {
        processedContent = processedContent 
          ? `${processedContent}\n\nüì∏ An√°lise da imagem:\n${imageAnalysis}`
          : `üì∏ An√°lise da imagem:\n${imageAnalysis}`;
        console.log("Updated content with image analysis");
      }
    }
    
    // Process audio - transcribe with Whisper
    if (messageType === "audio") {
      console.log("Starting audio transcription...");
      const transcription = await transcribeAudio(mediaUrl || "", base64Data);
      console.log("Transcription result:", transcription ? "Success" : "Failed/Empty");
      if (transcription) {
        processedContent = processedContent
          ? `${processedContent}\n\nüé§ Transcri√ß√£o do √°udio:\n${transcription}`
          : `üé§ Transcri√ß√£o do √°udio:\n${transcription}`;
        console.log("Updated content with transcription");
      }
    }
  } else {
    console.log("Skipping media processing - isFromMe:", isFromMe, "hasMedia:", !!(mediaUrl || base64Data));
  }

  // Get or create conversation
  const conversation = await getOrCreateConversation(
    instance.id,
    instance.organization_id,
    phone,
    senderName
  );

  // Save the message
  const direction = isFromMe ? "outbound" : "inbound";
  const savedMessage = await saveMessage(
    conversation.id,
    instance.id,
    processedContent,
    direction,
    messageType,
    messageId,
    mediaUrl,
    caption
  );

  console.log("WasenderAPI message processed:", {
    conversationId: conversation.id,
    from: phone,
    direction,
    text: processedContent?.substring(0, 50),
    saved: !!savedMessage,
    hadMediaProcessing: messageType === "image" || messageType === "audio"
  });

  // Generate and send AI response for incoming messages (if bot is enabled)
  if (!isFromMe && savedMessage && processedContent) {
    try {
      // Check if bot is enabled for this instance
      const { data: botConfig } = await supabase
        .from("whatsapp_bot_configs")
        .select("is_enabled, supervisor_mode, bot_name, company_name, main_objective, products_prices")
        .eq("instance_id", instance.id)
        .single();

      console.log("Bot config:", botConfig);

      if (botConfig?.is_enabled) {
        console.log("=== Bot enabled, generating intelligent response ===");
        
        // Get conversation history for context
        const conversationHistory = await getConversationHistory(conversation.id, 20);
        console.log("Fetched conversation history:", conversationHistory.length, "messages");

        // Get lead info if linked
        let leadInfo = null;
        if (conversation.lead_id) {
          const { data: lead } = await supabase
            .from("leads")
            .select("name, stage, products")
            .eq("id", conversation.lead_id)
            .single();
          leadInfo = lead;
        }

        // Generate AI response based on context
        const aiResponse = await generateAIResponse(
          conversationHistory,
          processedContent,
          leadInfo
        );

        if (aiResponse) {
          console.log("=== Sending AI response ===");
          console.log("Response preview:", aiResponse.substring(0, 100));

          // Send the AI response via WasenderAPI
          const apiKey = instance.wasender_api_key;
          if (apiKey) {
            const sendResponse = await fetch("https://www.wasenderapi.com/api/send-message", {
              method: "POST",
              headers: {
                "Authorization": `Bearer ${apiKey}`,
                "Content-Type": "application/json",
              },
              body: JSON.stringify({
                to: phone.startsWith("+") ? phone : `+${phone}`,
                text: aiResponse,
              }),
            });

            if (sendResponse.ok) {
              const sendData = await sendResponse.json();
              console.log("AI response sent successfully:", sendData);
              
              // Save the AI response to database
              await saveMessage(
                conversation.id,
                instance.id,
                aiResponse,
                "outbound",
                "text",
                sendData.data?.key?.id || undefined,
                undefined,
                undefined,
                true // isFromBot
              );
            } else {
              const errorText = await sendResponse.text();
              console.error("Failed to send AI response:", errorText);
            }
          }
        }
      } else {
        console.log("Bot not enabled for this instance");
      }
    } catch (botError) {
      console.error("Error in bot response generation:", botError);
      // Don't fail the webhook if bot fails
    }
  }

  return savedMessage;
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const body = await req.json();
    console.log("=== WhatsApp Multiattendant Webhook ===");
    console.log("Payload:", JSON.stringify(body, null, 2));

    // Detect provider from webhook payload structure
    let provider = "unknown";
    let instanceIdentifier = "";
    
    // WasenderAPI webhook format - check for sessionId (api_key) or event patterns
    if (body.sessionId || body.session_id || body.event?.startsWith("messages.") || body.event?.startsWith("session.")) {
      provider = "wasenderapi";
      // WasenderAPI sends api_key as sessionId in webhooks
      instanceIdentifier = String(body.sessionId || body.session_id || "");
      console.log("WasenderAPI webhook detected - sessionId (api_key):", instanceIdentifier);
    }
    // Z-API webhook format
    else if (body.instanceId || req.headers.get("x-instance-id")) {
      provider = "zapi";
      instanceIdentifier = body.instanceId || req.headers.get("x-instance-id") || "";
      console.log("Z-API webhook detected - instanceId:", instanceIdentifier);
    }
    
    console.log("Provider detected:", provider);
    console.log("Instance identifier:", instanceIdentifier);

    if (!instanceIdentifier) {
      console.log("No instance ID provided, ignoring webhook...");
      return new Response(JSON.stringify({ status: "ignored" }), {
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    // Find our instance
    const instance = await findInstance(instanceIdentifier, provider);
    if (!instance) {
      console.log("Instance not found:", instanceIdentifier);
      return new Response(JSON.stringify({ status: "instance_not_found" }), {
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    console.log("Instance found:", instance.name, instance.id, "provider:", instance.provider);

    // Handle WasenderAPI webhooks
    if (provider === "wasenderapi" || instance.provider === "wasenderapi") {
      const event = body.event;
      console.log("WasenderAPI event:", event);
      
      switch (event) {
        case "messages.received":
        case "messages.upsert": {
          // Process incoming or upserted messages
          const result = await processWasenderMessage(instance, body);
          return new Response(JSON.stringify({ 
            status: result ? "message_saved" : "message_skipped" 
          }), {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
          });
        }

        case "messages.update":
        case "messages.ack": {
          const messageId = body.data?.key?.id || body.data?.id || body.data?.messageId;
          const status = body.data?.status || body.data?.ack;

          if (messageId) {
            // Map WasenderAPI status codes to our status values
            const statusMap: Record<string, string> = {
              "sent": "sent",
              "delivered": "delivered",
              "read": "read",
              "0": "sent",
              "1": "sent",
              "2": "delivered",
              "3": "read",
              "4": "read", // Status 4 = played (for audio) or read
            };

            const newStatus = statusMap[String(status)] || "delivered";

            await supabase
              .from("whatsapp_messages")
              .update({ status: newStatus })
              .eq("z_api_message_id", messageId);

            console.log("Message status updated:", messageId, newStatus);
          }

          return new Response(JSON.stringify({ status: "status_updated" }), {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
          });
        }

        case "session.status": {
          const status = body.data?.status;
          const phone = body.data?.phone_number;

          if (status === "connected" || status === "ready") {
            await supabase
              .from("whatsapp_instances")
              .update({
                is_connected: true,
                phone_number: phone,
                status: "active",
                qr_code_base64: null,
              })
              .eq("id", instance.id);

            console.log("WasenderAPI instance connected:", instance.name, phone);
          } else if (status === "disconnected" || status === "qr" || status === "NEED_SCAN") {
            await supabase
              .from("whatsapp_instances")
              .update({
                is_connected: false,
                status: status === "NEED_SCAN" ? "pending" : "disconnected",
              })
              .eq("id", instance.id);

            console.log("WasenderAPI instance status:", instance.name, status);
          }

          return new Response(JSON.stringify({ status: "status_handled" }), {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
          });
        }

        default:
          console.log("Unknown WasenderAPI event:", event);
      }
    }

    // Handle Z-API webhooks (legacy)
    const webhookType = body.type || body.event;

    switch (webhookType) {
      case "ReceivedCallback":
      case "message":
      case "received": {
        const phone = body.phone || body.from?.replace("@c.us", "");
        let text = body.text?.message || body.body || body.message || "";
        const messageId = body.messageId || body.id;
        const isGroup = body.isGroup || false;
        const senderName = body.senderName || body.pushName || body.notifyName;
        const senderPhoto = body.senderPhoto || body.profilePicUrl;
        const messageType = body.type || "text";
        const mediaUrl = body.image?.imageUrl || body.audio?.audioUrl || body.video?.videoUrl || body.document?.documentUrl;
        const caption = body.caption;

        if (!phone) {
          console.log("No phone number in message");
          return new Response(JSON.stringify({ status: "no_phone" }), {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
          });
        }

        if (isGroup) {
          console.log("Group message, skipping...");
          return new Response(JSON.stringify({ status: "group_ignored" }), {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
          });
        }

        // Process media for Z-API
        let processedContent = text || caption || null;
        
        if (mediaUrl) {
          // Process image
          if (messageType === "image" || body.image?.imageUrl) {
            const imageAnalysis = await analyzeImage(mediaUrl);
            if (imageAnalysis) {
              processedContent = processedContent 
                ? `${processedContent}\n\nüì∏ An√°lise da imagem:\n${imageAnalysis}`
                : `üì∏ An√°lise da imagem:\n${imageAnalysis}`;
            }
          }
          
          // Process audio
          if (messageType === "audio" || body.audio?.audioUrl) {
            const transcription = await transcribeAudio(mediaUrl);
            if (transcription) {
              processedContent = `üé§ Transcri√ß√£o do √°udio:\n${transcription}`;
            }
          }
        }

        const conversation = await getOrCreateConversation(
          instance.id,
          instance.organization_id,
          phone,
          senderName,
          senderPhoto
        );

        await saveMessage(
          conversation.id,
          instance.id,
          processedContent,
          "inbound",
          messageType,
          messageId,
          mediaUrl,
          caption
        );

        console.log("Z-API message saved:", {
          conversationId: conversation.id,
          from: phone,
          text: processedContent?.substring(0, 50),
        });

        return new Response(JSON.stringify({ status: "message_saved" }), {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }

      case "MessageStatusCallback":
      case "status":
      case "ack": {
        const messageId = body.messageId || body.id;
        const status = body.status || body.ack;

        if (messageId) {
          const statusMap: Record<string, string> = {
            "SENT": "sent",
            "RECEIVED": "delivered",
            "READ": "read",
            "PLAYED": "read",
            "1": "sent",
            "2": "delivered",
            "3": "read",
            "4": "read",
          };

          const newStatus = statusMap[String(status)] || status;

          if (newStatus) {
            await supabase
              .from("whatsapp_messages")
              .update({ status: newStatus })
              .eq("z_api_message_id", messageId);

            console.log("Z-API Message status updated:", messageId, newStatus);
          }
        }

        return new Response(JSON.stringify({ status: "status_updated" }), {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }

      case "ConnectedCallback":
      case "connected": {
        const phone = body.phone || body.phoneNumber;

        await supabase
          .from("whatsapp_instances")
          .update({
            is_connected: true,
            phone_number: phone,
            status: "active",
            qr_code_base64: null,
          })
          .eq("id", instance.id);

        console.log("Z-API instance connected:", instance.name, phone);

        return new Response(JSON.stringify({ status: "connected" }), {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }

      case "DisconnectedCallback":
      case "disconnected": {
        await supabase
          .from("whatsapp_instances")
          .update({
            is_connected: false,
            status: "disconnected",
          })
          .eq("id", instance.id);

        console.log("Z-API instance disconnected:", instance.name);

        return new Response(JSON.stringify({ status: "disconnected" }), {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }
    }

    console.log("Unhandled webhook type:", webhookType);
    return new Response(JSON.stringify({ status: "ignored" }), {
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  } catch (error: any) {
    console.error("Webhook error:", error);
    return new Response(JSON.stringify({ error: error.message }), {
      headers: { ...corsHeaders, "Content-Type": "application/json" },
      status: 500,
    });
  }
});
